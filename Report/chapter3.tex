\chapter{روش‌های ارائه‌شده}
در این فصل قرار است سه روش انتخاب ویژگی برای مسائل دسته‌بندی بررسی شود. لازم به ذکر است که در این فصل روش‌ها عینا مطابق با چیزی که در متن مقاله گفته شده است بیان نشده است؛ یعنی آنکه برخی از جزئیات حذف شده است و ممکن است نحوه بیان برخی از قسمت‌های روش تغییر یافته باشد. با تمام این‌ها ایده و خروجی روش‌ها کاملا منطبق بر چیزی است که در مقالات بیان شده است.


\section{روش \lr{IGFSS}} 
روش \lr{IGFSS} توسط اویسال\cite{uysal2016improved} معرفی شده است و این بخش بر اساس مقاله وی تبیین شده است. ابتدا این روش را معرفی می‌کنیم و سپس مثالی برای اجرای این الگوریتم در ادامه خواهیم آورد.
\subsection{مراحل الگوریتم}
این الگوریتم از چهار گام تشکیل شده است:
\begin{enumerate}
\item \textbf{برچسب‌گذاری ویژگی‌ها}: در این گام برای هر ویژگی یک امتیاز انتخاب ویژگی محلی نسبت به هر کلاس محاسبه می‌شود. هر کدام از این ویژگی‌ها عضویت یا عدم عضویت یک کلاس نسبت به سایر کلاس‌ها را بهتر نمایش می‌دهد. در این مرحله با یک برچسب شماره کلاس و عضویت یا عدم عضویت یک ویژگی را مشخص می‌کنیم. 
\item \textbf{انتخاب ویژگی جهانی}: این بار با یک شاخص انتخاب ویژگی جهانی برای هر ویژگی امتیاز آن را محاسبه می‌کنیم و لیست را بر اساس این امتیاز مرتب می‌کنیم. 
\item \textbf{ساخت مجموعه ویژگی}: فرض کنید که اندازه مجموعه ویژگی‌های انتخاب شده برابر با 
$fs$
باشد. همچنین فرض کنید که نسبت تعداد ویژگی‌های منفی به کل ویژگی‌ها برابر با
$nfrs$
باشد. در این مرحله از ابتدای لیستی که در گام قبل ساخته شده است به سمت انتهای لیست حرکت می‌کنیم. برای هر کلاس و با توجه به برچسب‌هایی که در گام اول مشخص کردیم ویژگی‌ها با بیشترین امتیاز جهانی را انتخاب می‌کنیم و در عین حال باید نسبت ویژگی‌های منفی و مثبت رعایت شود.
\item \textbf{بخش شرطی}: چنانچه اندازه مجموعه ویژگی‌های انتخاب شده کمتر از $fs$ باشد، لازم است تا تعدادی ویژگی به مجموعه اضافه شود. این ویژگی‌ها را بر اساس معیار انتخاب ویژگی جهانی انتخاب می‌شوند. یعنی ویژگی‌ها با بیشترین امتیاز که تا به الان انتخاب نشده‌اند به مجموعه ویژگی‌های انتخاب‌شده افزوده می‌شوند تا به اندازه مورد نظر برسیم.
\end{enumerate}

\subsection{مثال و تحلیل}
برای درک بهتر از نحوه اجرای الگوریتم بهتر است تا یک مثال را مورد بررسی قرار دهیم.\cite{uysal2016improved}  در جدول ۳-۱ یک مجموعه‌داده کوچک شامل محتوا و کلاس اسناد آورده شده است. 

\begin{table}
\begin{center}
\caption{مجموعه‌داده نمونه برای روش \lr{IGFSS}}
\begin{tabular}{r|r|r}
\toprule
\textbf{شماره سند} & \textbf{محتوای سند} & \textbf{کلاس}
\\
\hline
\hline
۱ & موش گربه گرگ & $C_1$
\\
۲ & موش گربه اسب سگ & $C_2$
\\
۳ & موش گربه سگ مرغ اسب & $C_2$
\\
۴ & خفاش گاو اردک اسب پلیکان & $C_3$
\\
۵ & خفاش گاو اسب پلیکان & $C_3$
\\
۶ & خفاش گاو شتر اسب مرغ & $C_3$
\\
\bottomrule
\end{tabular}
\end{center}
\end{table}

بر اساس مجموعه‌داده معرفی‌شده می‌توان معیار‌های انتخاب ویژگی مرتبط را بدست آورد و برچسب‌گذاری پیشنهادی در گام اول الگوریتم را انجام داد. خروجی این موارد در جدول ۳-۲ آورده شده است. 

\begin{table}
\begin{center}
\caption{امتیاز معیار‌های انتخاب ویژگی برای روش \lr{IGFSS}}
\begin{tabular}{r|r|r|r}
\toprule
\textbf{ویژگی} & \textbf{امتیاز شاخص جینی} & \textbf{امتیاز نسبت نابرابری کلاس‌ها} & \textbf{برچسب ویژگی}
\\
\hline
\hline
خفاش & ۱ & ۴/۱۱۰۹- ، ۴/۳۳۰۷- ، ۴/۶۱۵۱ & $C_3$ مثبت
\\
گاو & ۱ & ۴/۱۱۰۹- ، ۴/۳۳۰۷- ، ۴/۶۱۵۱ & $C_3$ مثبت
\\
سگ & ۱ & ۳/۷۱۳۶- ، ۴/۶۱۵۱ ، ۴/۲۱۴۶- & $C_2$ مثبت
\\
گرگ & ۱ & ۴/۶۱۵۱ ، ۳/۲۵۸۱- ، ۳/۵۳۶۱- & $C_1$ مثبت
\\
گربه & ۰/۵۵۵۶ & ۴/۱۱۰۹ ، ۴/۳۳۰۷ ، ۴/۶۱۵۱- & $C_3$ منفی
\\
موش & ۰/۵۵۵۶ & ۴/۱۱۰۹ ، ۴/۳۳۰۷ ، ۴/۶۱۵۱- & $C_3$ منفی
\\
اسب & ۰/۵۲۰۰ & ۴/۶۱۵۱- ، ۳/۲۵۸۱ ، ۳/۵۳۶۱ & $C_1$ منفی
\\
پلیکان & ۰/۴۴۴۴ & ۳/۷۱۳۶- ، ۳/۹۳۱۸- ، ۳/۸۱۶۵ & $C_2$ منفی
\\
اردک & ۰/۱۱۱۱ & ۳/۰۴۴۵- ، ۳/۲۵۸۱- ، ۲/۴۹۴۱ & $C_2$ منفی
\\
شتر & ۰/۱۱۱۱ & ۳/۰۴۴۵- ، ۳/۲۵۸۱- ، ۲/۴۹۴۱ & $C_2$ منفی
\\
مرغ & ۰/۰۹۰۳ & ۳/۷۱۳۶- ، ۰ ، ۱/۲۹۲۹- & $C_1$ منفی
\\

\bottomrule 
\end{tabular}
\end{center}
\end{table}



\begin{table}
\begin{center}
\caption{تفاوت روش سنتی با روش \lr{IGFSS} برای مثال ارائه‌شده}
\begin{tabular}{r|r|r|r|r}
\toprule
\textbf{روش}&\textbf{مجموعه ویژگی‌های انتخاب‌شده}&\textbf{$C_1$} & \textbf{$C_2$} & \textbf{$C_3$}
\\
\hline
\hline
روش سنتی برپایه شاخص جینی & خفاش، گاو، سگ، گرگ، گربه و موش & ۱ & ۱ & ۴
\\
روش \lr{IGFSS} & خفاش، سگ، گرگ، گربه، اسب و پلیکان & ۲ & ۲ & ۲
\\
\bottomrule
\end{tabular}
\end{center}
\end{table}

\section{روش \lr{MRDC}}
روش \lr{} توسط لبنی و همکاران \cite{labani2018novel} ارائه شده است. مانند قسمت قبل ابتدا روش را تشریح می‌کنیم و سپس سعی می‌کنیم در قالب یک مثال تحلیل اولیه از آن داشته باشیم.

\subsection{مراحل الگوریتم}

\begin{enumerate}
\item پیش‌پردازش: به طور خلاصه پردازش‌های زیر بر روی داده‌ها انجام می‌شود:

\begin{itemize}

\item حذف ایست‌واژه‌‌ها\LTRfootnote{Stop word}: برخی از کلمات نظیر حروف اضافه در غالب اسناد به تعداد بالا یافت می‌شود و لذا دانش مفیدی برای دسته‌بندی متون نداند که بهتر است حذف شوند.
\item حذف کلمات نادر: تعدادی از کلمات هستند که تنها در تعداد بسیار کمی از اسناد ظاهر می‌شوند. مطابق با قانون \lr{Zipf} تعداد این کلمات بسیار زیاد است و حذف آن باعث کاهش چشمگیر تعداد ویژگی‌ها می‌شود. در روش مقاله کلماتی که در کمتر از چهار سند آمده‌اند را حذف کرده‌اند.
\item ریشه‌یابی\LTRfootnote{Stemming}: خیلی از کلمات هستند که به طریق مختلف نوشته می‌شوند ولی به یک کلمه مرتبط هستند؛ به عنوان مثال کلمات «می‌روم»، «رفت»، «بروید» تماما ریشه یکسانی دارند. در روش پیشنهادی نیز از ریشه‌یابی استفاده شده است.
\end{itemize}

\item محاسبه امتیاز جهانی: در گام بعد برای تمام ویژگی‌های باقی مانده امتیاز ویژگی مطابق با معیار تمایزگر نسبی محاسبه می‌شود.

\item انتخاب ویژگی‌‌ها: در این گام سعی در انتخاب ویژگی‌هایی است که هم امتیاز جهانی بالایی داشته باشند و هم آنکه همبستگی کمی با یکدیگر داشته باشند. مجموعه 
$S$
مجموعه ویژگی‌های انتخاب‌شده نهایی است. در ابتدا این مجموعه با ویژگی‌ای که بیشترین امتیاز جهانی را داشته باشد تشکیل می‌شود. سپس به صورت تکرارشونده ویژگی که دارای بالاترین امتیاز 
$MRDC$
باشد به مجموعه
$S$
افزوده می‌شود تا مجموعه
$S$
به اندازه مدنظر برسد. نحوه محاسبه معیار
$MRDC$
به ازای ویژگی 
$f_i$
در رابطه ۳-۱ آورده شده است.

\begin{equation}
MRDC(f_i) = RDC(f_i) - \sum_{f_i \ne j_j, f_j \in S} correlation(f_i, f_j)
\end{equation}
 
\end{enumerate}

\subsection{مثال و تحلیل}


\begin{table}
\begin{center}
\caption{مجموعه‌داده نمونه برای روش \lr{MRDC}}
\begin{tabular}{r|r|r}
\toprule
\textbf{شماره سند} & \textbf{محتوای سند} & \textbf{کلاس}
\\
\hline
\hline
۱ & گربه ماهی & $C_1$
\\
۲ & گربه موش ماهی & $C_1$
\\
۳ & موش ماهی & $C_1$
\\
۴ & موش گربه ماهی موش ماهی & $C_1$
\\
۵ & ماهی گربه ماهی گربه & $C_1$
\\
۶ & ماهی موش & $C_1$
\\
۷ & سگ موش & $C_2$
\\
۸ & سگ سگ & $C_2$
\\
۹ & ماهی ماهی موش & $C_2$
\\
۱۰ & موش & $C_2$
\\
۱۱ & گربه ماهی & $C_2$
\\
۱۲ & سگ ماهی & $C_2$
\\

\bottomrule
\end{tabular}
\end{center}
\end{table}





\section{روش برپایه الگوریتم ژنتیک}
در کار تحقیقاتی غارب و همکاران\cite{ghareb2016hybrid} برای انتخاب ویژگی‌های مسائل دسته‌بندی از روشی مبتنی بر الگوریتم ژنتیک بهره گرفتند. این بخش این روش را تشریح می‌کند. ه
\subsection{شناسنامه الگوریتم ژنتیک}
مانطور که در فصل قبل در مورد الگوریتم‌های ژنتیک توضیح دادیم، برای ارائه یک الگوریتم بر پایه ژنتیک باید گام‌ها و توابع موجود در آن را به طور دقیق تعریف کرد. توابع و جزئیاتی پیشنهادی آنان به شرح زیر است:
\begin{enumerate}
\item بازنمایی: هر ژن در یک کرومزوم متناسب با ويژگی است. در صورتی که مقدار آن صفر باشد یعنی آن ویژگی انتخاب نشده است و اگر مقدار آن یک باشد یعنی ویژگی انتخاب شده است.
\item جمعیت اولیه: برای ساخت جمعیت اولیه به صورت کاملا تصادفی کروموزم‌ها ساخته می‌شود.
\item تابع شایستگی: تابع شایستگی در این مقاله به دو هدف اهمیت می‌دهد؛ اول آنکه مجموعه ویژگی انتخاب شده باید برای دسته‌بندی مناسب باشد و دوم آنکه باید حتی الامکان اندازه آن کوچک باشد. در رابطه ۳-۲ تابع شایستگی آورده شده است. پارامتر
$z$
برای تنظیم نسبت اهمیت دو مولفه گفته شده است. در مقاله از عدد ۰/۸ برای آن استفاده کرده‌اند.
$c(s_i)$
امتیاز مجموعه ویژگی را مشخص می‌کند.

\begin{equation}
fitness(s_i) = z.c(s_i) + (1-z).\frac{1}{|s_i|}
\end{equation}

\item انتخاب: انتخاب افراد برتر باتوجه به امتیاز شایستگی تعیین می‌شود. مطابق با رابطه ۳-۳ احتمال انتخاب هر فرد تعیین می‌شود.

\begin{equation}
p(s_i) = \frac{fitness(s_i)}{\sum_{i=1}^n fitness(s_i)}
\end{equation}

\item باز ترکیبی: برای بازترکیبی، هر کرومزوم والد به دو بخش کاملا مساوی تقسیم می‌شود. سپس بر اساس وزن‌های \lr{TF-IDF} مشخص می‌شود که هر بخش از هر کرومزوم والد دارای چه مجموع وزنی است. سپس یک فرزند را از دو قسمتی می‌سازند که بیشترین وزن ممکن به وجود آید و یک فرزند را از دو بخش باقی‌مانده.
\item جهش: برای جهش در روش پیشنهادی مقاله، ابتدا بررسی می‌شود که آیا امتیاز والدین یک فرزند از یک حد آستانه‌ای پایین‌تر است یا خیر. اگر پایین‌تر بود ژن‌های فرزند باید تغییر کند. برای جهش، تعدادی از ویژگی‌ها با پایین‌ترین وزن حذف می‌شود و به جای آن ویژگی‌ها با اهمیت بالا در بهترین کرومزوم نسل قبل جایگزین می‌شود.
\end{enumerate}

\subsection{مراحل الگوریتم}
روش پیشنهادی غارب و همکاران در دو گام اصلی انجام می‌گیرد:
\begin{enumerate}
\item انتخاب ویژگی‌های برتر: در این گام و با کمک معیارهای انتخاب ویژگی با نگرش روش‌های فیلتر، بهترین ویژگی‌ها انتخاب می‌شود. این ویژگی‌ها ویژگی نهایی نیست؛ بلکه در این گام سعی شده است تا تعداد ویژگی‌های اصلی که بسیار زیاد است را به تعداد معقولی کاهش دهد تا اجرای یک الگوریتم ژنتیک امکان‌پذیر باشد.
\item اجرای الگوریتم ژنتیک: در این گام مطابق با توضیحات بخش قبل الگوریتم ژنتیک اجرا می‌شود. در اینجا لازم به ذکر است که برای محاسبه مناسب بودن یک مجموعه ویژگی از روش‌های پوشاننده استفاده می‌شود. نهایتا در خروجی این گام یک مجموعه ویژگی نهایی حاصل می‌گردد.
\end{enumerate}